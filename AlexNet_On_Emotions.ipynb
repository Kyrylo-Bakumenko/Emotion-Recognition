{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy\n",
    "from PIL import ImageOps\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from matplotlib import cm\n",
    "\n",
    "REBUILD_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('training_data_alex.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5538/5538 [03:05<00:00, 29.85it/s]\n"
     ]
    }
   ],
   "source": [
    "if REBUILD_DATA:\n",
    "    # Create rotated set\n",
    "    training_data_rotated = []\n",
    "    for img in training_data:\n",
    "        training_data_rotated.append(img)\n",
    "        for i in range(1,13):\n",
    "            training_data_rotated.append([scipy.ndimage.rotate(img[0], i, reshape=False), img[1].reshape(1000)])\n",
    "\n",
    "\n",
    "    # Create flipped set\n",
    "    training_data_r_f = []\n",
    "    for img in training_data_rotated:\n",
    "        training_data_r_f.append(img)\n",
    "        training_data_r_f.append([np.fliplr(img[0]), img[1]])\n",
    "\n",
    "#     remove un-needed noise\n",
    "    def dumb_remover(img):\n",
    "        better_img = np.ndarray((224, 224, 3))\n",
    "        for row in range(len(img)):\n",
    "            for col in range(len(img[row])):\n",
    "                better_img[row][col] = img[row][col]\n",
    "                \n",
    "        return better_img\n",
    "\n",
    "\n",
    "    for i in tqdm(range(len(training_data_r_f))):\n",
    "        training_data_r_f[i][0] = dumb_remover(training_data_r_f[i][0]).reshape(224, 224, 3)\n",
    "\n",
    "    # shuffle for good luck\n",
    "    np.random.shuffle(training_data_r_f)\n",
    "\n",
    "    # Save\n",
    "    np.save('training_data_rotated_and_flipped_alex.npy', training_data_r_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('training_data_rotated_and_flipped_alex.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  torch.Size([5538, 224, 224, 3])\n",
      "y shape:  torch.Size([5538, 1000])\n",
      "5538 2215\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([i[0] for i in training_data]).view(-1, 224, 224, 3)\n",
    "X = X/255.0\n",
    "print(\"X shape: \", X.shape)\n",
    "\n",
    "y = torch.Tensor([i[1] for i in training_data])\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "VAL_PCT = 0.4\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "print(len(X), val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3323\n",
      "2215\n"
     ]
    }
   ],
   "source": [
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.alexnet(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AlexNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet = nn.DataParallel(alexnet)\n",
    "alexnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\baby yoda\\pycharmprojects\\dltutorial_2\\venv\\lib\\site-packages\\torch\\cuda\\nccl.py:24: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out/Sample Accuracy:  0.195\n",
      "Loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Out/Sample Accuracy:  0.195\n",
      "Loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Out/Sample Accuracy:  0.195\n",
      "Loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Out/Sample Accuracy:  0.195\n",
      "Loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Out/Sample Accuracy:  0.195\n",
      "Loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "optimizer = optim.Adam(alexnet.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "loss_outsample = []\n",
    "acc = []\n",
    "loss_insample = []\n",
    "\n",
    "alex_model_max = alexnet\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    alexnet.train()\n",
    "    for i in range(0, len(train_X), BATCH_SIZE):\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 3, 224, 224)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "        \n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        alexnet.zero_grad()\n",
    "        outputs = alexnet(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    max_accuracy = 0\n",
    "    max_loss = 10\n",
    "    \n",
    "    alexnet.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(test_X)):\n",
    "            real_class = torch.argmax(test_y[i]).to(device)\n",
    "            model_out = alexnet(test_X[i].view(-1, 3, 224, 224).to(device))[0]\n",
    "            predicted_class = torch.argmax(model_out)\n",
    "#             print(predicted_class, real_class)\n",
    "            loss_test = loss_function(model_out, test_y[i].to(device))\n",
    "            if predicted_class == real_class:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    acc.append(round(correct/total, 4))\n",
    "    print(\"Out/Sample Accuracy: \", round(correct/total, 3))\n",
    "    loss_outsample.append(loss_test)\n",
    "    loss_insample.append(loss)\n",
    "    print(\"Loss: \", loss)\n",
    "    if round(correct/total, 3) > max_accuracy:\n",
    "        max_accuracy = round(correct/total, 3)\n",
    "        max_loss = loss\n",
    "        alex_model_max = alexnet\n",
    "    elif (round(correct/total, 3) == max_accuracy) and (loss < max_loss):\n",
    "        max_loss = loss\n",
    "        alex_model_max = alexnet\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
